<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Welcom to whmz&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="知识整理和分享">
<meta property="og:type" content="website">
<meta property="og:title" content="Welcom to whmz&#39;s Blog">
<meta property="og:url" content="http://whmz.github.io/index.html">
<meta property="og:site_name" content="Welcom to whmz&#39;s Blog">
<meta property="og:description" content="知识整理和分享">
<meta property="og:locale" content="zh-cn">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Welcom to whmz&#39;s Blog">
<meta name="twitter:description" content="知识整理和分享">
  
    <link rel="alternate" href="/atom.xml" title="Welcom to whmz&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Welcom to whmz&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">总结，进步，分享</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://whmz.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-net-cpuset" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/24/net-cpuset/" class="article-date">
  <time datetime="2018-03-24T11:45:05.000Z" itemprop="datePublished">2018-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/24/net-cpuset/">网卡中断和CPU绑定问题处理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>继续网关优化话题，本次整理下处理的一个CPU绑定问题。</p>
<p>在CPU绑定一块，有几个工具是可以使用的：</p>
<ol>
<li><p>taskset - set or retrieve a process’s CPU affinity<br>可以设定或取消某个进程的CPU亲和（我觉得叫绑定不错）。具体使用上，可以设置mask选择某个CPU核，直接给进程设定CPU编号。</p>
</li>
<li><p>set_irq_affinity - 设置网卡中断的CPU绑定关系<br>Intel随ixgeb驱动源码一起提供的一个脚本，一般位于 ixgbe-x.x.x\scripts\set_irq_affinity。脚本根据传入的CPU核心号及网卡名，动态计算绑定关系并设置。</p>
</li>
<li><p>htop - interactive process viewer<br>可以动态、以图形方式查看各个CPU核心的负载，以及占用CPU较高的当前进程。在调试过程中，可以用来动态观察CPU核心负载，判断哪些CPU负载较高。</p>
</li>
<li><p>/proc/interrupts - 中断信息<br>可以看到当前各个中断数、以及每个CPU处理的中断数，并能根据后面几列查看是哪个网卡、队列等信息。</p>
</li>
</ol>
<h2 id="问题时间点"><a href="#问题时间点" class="headerlink" title="问题时间点"></a>问题时间点</h2><p>在网络运营中，比较经常收到用户投诉，报高峰期的上网不稳定、延迟比较大、有时间段无法连接等问题。为了排查问题，在几个高峰时间点跟踪了下CPU状态、网络负载情况，发现有几个CPU核心负载非常高，明显超出其他CPU核心，并多次达到90%以上的利用率。按之前的设置理解，Intel-82599ES网卡应该已经对数据做了Hash处理、分到各个队列去执行收发操作；set_irq_affinity也已经对各个中断做了绑定，按理说不应该出现非常不均衡的情况，除非：某些访问非常占用资源，而且这种访问在Hash意义上不均衡；CPU亲和没有均衡各个中断，导致各CPU实际处理的中断不均衡。</p>
<h2 id="原始脚本和绑定关系"><a href="#原始脚本和绑定关系" class="headerlink" title="原始脚本和绑定关系"></a>原始脚本和绑定关系</h2><p>处理流量的网关本身配置2CPU，共24核心、48线程，其中0-11，24-35为一个CPU，12-23，36-47为另一个CPU；使用了Intel-82599ES网卡，配两个万兆光模块，一进一出；在之前为了解决高峰期处理用户连接响应慢的问题，给strongswan进程绑定了40-47号CPU，给外网卡绑定了8-11+24-35共16个核心，内网卡则使用了12-23+36-39共16个核心。按原始规划，外网卡不负责数据加解密，只会收发数据，负载应该不会太高。</p>
<p>放几个脚本：</p>
<ol>
<li>set_charon_cpu.sh <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># CPU_SET_GROUP_TASK 外部传入，目前40-47</span></span><br><span class="line"></span><br><span class="line">CPU_SET_GROUP_TASK=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line">pid=`pidof charon`</span><br><span class="line">tlist=`ls /proc/<span class="variable">$&#123;pid&#125;</span>/task`</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> tid <span class="keyword">in</span> <span class="variable">$&#123;tlist&#125;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  taskset -cp <span class="string">"<span class="variable">$CPU_SET_GROUP_TASK</span>"</span> <span class="variable">$tid</span></span><br><span class="line">  <span class="comment">#echo $&#123;tid&#125;    </span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>脚本获取charon进程pid，并根据pid找到关联的进程，设置相应任务的CPU</p>
<ol>
<li>set_irq_affinity<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set_irq_affinity &quot;$CPU_SET_GROUP_IDEV&quot; $IDEV</span><br><span class="line">set_irq_affinity &quot;$CPU_SET_GROUP_ODEV&quot; $ODEV</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>设置网卡中断亲和，按前述CPU核心关系设置</p>
<h2 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h2><p>按分析，问题点分到了两个方向，Intel-82599ES的队列Hash是否均衡，以及CPU亲和设置是否正确。</p>
<ol>
<li>检查82599的队列Hash过程<br>翻看了<a href="https://www.intel.com/content/dam/www/public/us/en/documents/datasheets/82599-10-gbe-controller-datasheet.pdf" target="_blank" rel="noopener">Intel 82599 10 GbE Controller Datasheet</a>,其中7.1.2.7.15节，以及7.1.2.8.1节，给出了Hash函数的伪码，并给出了对应的输入情况。其中还提到，该算法来源自微软<a href="https://docs.microsoft.com/en-us/windows-hardware/drivers/network/rss-hashing-functions" target="_blank" rel="noopener">MSFT RSS</a>。另外，在整理这篇的时候，想到一个问题，翻看了下ixgbe驱动的README，在其中也看到些关于RSS、HASH的说法。</li>
</ol>
<p>综合起来说，HASH函数不复杂，但是参数不少，而且计算过程有几个参数随机，基本上意味着比较困难分析结果的随机性，除非做散列测试和统计。分析这个对于解决问题帮助不大，后续放弃了这个排查方向。</p>
<ol>
<li>CPU亲和设置<br>结合Hash队列的排查，想到一个问题解决办法，如果某个核心的中断数太多，给该中断指定多个CPU核心处理是否可行？</li>
</ol>
<p>为了验证这个思路，先得把CPU和中断的绑定关系找到，使用/proc/interrupts系统，获取系统的中断情况：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用grep过滤了带CPU信息的首行、以及带网卡名的所有行</span></span><br><span class="line">cat /proc/interrupts | grep -E "CPU|ens3f"&gt; inter.1.txt</span><br></pre></td></tr></table></figure></p>
<p>得到的结果比较大，基本没法分析，大致是这个样子：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">          CPU0       CPU1       CPU2       CPU3       CPU4       CPU5       CPU6       CPU7       CPU8       CPU9       CPU10      CPU11      CPU12      CPU13      CPU14      CPU15      CPU16      CPU17      CPU18      CPU19      CPU20      CPU21      CPU22      CPU23      CPU24      CPU25      CPU26      CPU27      CPU28      CPU29      CPU30      CPU31      CPU32      CPU33      CPU34      CPU35      CPU36      CPU37      CPU38      CPU39      CPU40      CPU41      CPU42      CPU43      CPU44      CPU45      CPU46      CPU47      </span><br><span class="line">79:          2          0          0          0          0          0          0          0          0          0          0          0  152046289          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI 2621440-edge      ens3f0-TxRx-0</span><br><span class="line">80:          0          2          0          0          0          0          0          0          0          0          0          0          0 3544103245          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI 2621441-edge      ens3f0-TxRx-1</span><br><span class="line">81:          0          0          2          0          0          0          0          0          0          0          0          0          0          0 3613272673          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI 2621442-edge      ens3f0-TxRx-2</span><br></pre></td></tr></table></figure></p>
<p>为了方便处理，先分析问题严重的网卡ens3f1，再对数据做个过滤，只留下外网卡关联的数据、CPU核心,导入到excel中，并对数据做了个标准化（数据太大，统一除1000000之后取整，方便肉眼观察）:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">	CPU8	CPU9	CPU10	CPU11	CPU24	CPU25	CPU26	CPU27	CPU28	CPU29	CPU30	CPU31	CPU32	CPU33	CPU34	CPU35		</span><br><span class="line">129:	1940 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-0</span><br><span class="line">130:	0 	1958 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-1</span><br><span class="line">131:	0 	0 	1952 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-2</span><br><span class="line">132:	0 	0 	0 	1937 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-3</span><br><span class="line">133:	0 	0 	0 	0 	1882 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-4</span><br><span class="line">134:	0 	0 	0 	0 	0 	1874 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-5</span><br><span class="line">135:	0 	0 	0 	0 	0 	0 	1867 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-6</span><br><span class="line">136:	0 	0 	0 	0 	0 	0 	0 	1836 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-7</span><br><span class="line">137:	0 	0 	0 	0 	0 	0 	0 	0 	2089 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-8</span><br><span class="line">138:	0 	0 	0 	0 	0 	0 	0 	0 	0 	2110 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-9</span><br><span class="line">139:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	2118 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-10</span><br><span class="line">140:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	2100 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-11</span><br><span class="line">141:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	752 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-12</span><br><span class="line">142:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	962 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-13</span><br><span class="line">143:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	296 	0 	IR-PCI-MSI	ens3f1-TxRx-14</span><br><span class="line">144:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	565 	IR-PCI-MSI	ens3f1-TxRx-15</span><br><span class="line">145:	3208 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-16</span><br><span class="line">146:	0 	2788 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-17</span><br><span class="line">147:	0 	0 	3094 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-18</span><br><span class="line">148:	0 	0 	0 	3706 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-19</span><br><span class="line">149:	0 	0 	0 	0 	3429 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-20</span><br><span class="line">150:	0 	0 	0 	0 	0 	3359 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-21</span><br><span class="line">151:	0 	0 	0 	0 	0 	0 	3428 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-22</span><br><span class="line">152:	0 	0 	0 	0 	0 	0 	0 	3276 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-23</span><br><span class="line">153:	0 	0 	0 	0 	0 	0 	0 	0 	67 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-24</span><br><span class="line">154:	0 	0 	0 	0 	0 	0 	0 	0 	0 	67 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-25</span><br><span class="line">155:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	67 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-26</span><br><span class="line">156:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	68 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-27</span><br><span class="line">157:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	58 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-28</span><br><span class="line">158:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	58 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-29</span><br><span class="line">159:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	58 	0 	IR-PCI-MSI	ens3f1-TxRx-30</span><br><span class="line">160:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	59 	IR-PCI-MSI	ens3f1-TxRx-31</span><br><span class="line">161:	64 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-32</span><br><span class="line">162:	0 	64 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-33</span><br><span class="line">163:	0 	0 	63 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-34</span><br><span class="line">164:	0 	0 	0 	65 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-35</span><br><span class="line">165:	0 	0 	0 	0 	3573 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-36</span><br><span class="line">166:	0 	0 	0 	0 	0 	3288 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-37</span><br><span class="line">167:	0 	0 	0 	0 	0 	0 	3426 	0 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-38</span><br><span class="line">168:	0 	0 	0 	0 	0 	0 	0 	3692 	0 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-39</span><br><span class="line">169:	0 	0 	0 	0 	0 	0 	0 	0 	2 	0 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-40</span><br><span class="line">170:	0 	0 	0 	0 	0 	0 	0 	0 	0 	2 	0 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-41</span><br><span class="line">171:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	2 	0 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-42</span><br><span class="line">172:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	2 	0 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-43</span><br><span class="line">173:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	2 	0 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-44</span><br><span class="line">174:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	2 	0 	0 	IR-PCI-MSI	ens3f1-TxRx-45</span><br><span class="line">175:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	2 	0 	IR-PCI-MSI	ens3f1-TxRx-46</span><br><span class="line">176:	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	2 	IR-PCI-MSI	ens3f1-TxRx-47</span><br></pre></td></tr></table></figure></p>
<p>这个图已经比较明显看到了问题。其中24-27号CPU，每个都处理了三组中断，这就是在htop图形上，这三个CPU负载极高的内在原因：处理了比其他CPU多50%的中断。可这是为什么，不是已经做了均衡了吗？？</p>
<p>使用ethtool，查看下网卡的统计信息，关联之前的中断号如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">	tx	rx	</span><br><span class="line">129:	25 	202819 	ens3f1-TxRx-0</span><br><span class="line">130:	10 	200887 	ens3f1-TxRx-1</span><br><span class="line">131:	8 	197607 	ens3f1-TxRx-2</span><br><span class="line">132:	7 	199917 	ens3f1-TxRx-3</span><br><span class="line">133:	8 	200718 	ens3f1-TxRx-4</span><br><span class="line">134:	7 	200328 	ens3f1-TxRx-5</span><br><span class="line">135:	6 	198601 	ens3f1-TxRx-6</span><br><span class="line">136:	6 	199398 	ens3f1-TxRx-7</span><br><span class="line">137:	1441 	199485 	ens3f1-TxRx-8</span><br><span class="line">138:	1462 	199248 	ens3f1-TxRx-9</span><br><span class="line">139:	1525 	200840 	ens3f1-TxRx-10</span><br><span class="line">140:	1388 	199782 	ens3f1-TxRx-11</span><br><span class="line">141:	115844 	1412115 	ens3f1-TxRx-12</span><br><span class="line">142:	120249 	1310274 	ens3f1-TxRx-13</span><br><span class="line">143:	110647 	1260492 	ens3f1-TxRx-14</span><br><span class="line">144:	113217 	1346577 	ens3f1-TxRx-15</span><br><span class="line">145:	103214 	1004918 	ens3f1-TxRx-16</span><br><span class="line">146:	90486 	893424 	ens3f1-TxRx-17</span><br><span class="line">147:	90040 	918054 	ens3f1-TxRx-18</span><br><span class="line">148:	102377 	1072487 	ens3f1-TxRx-19</span><br><span class="line">149:	116699 	1087521 	ens3f1-TxRx-20</span><br><span class="line">150:	111154 	1025848 	ens3f1-TxRx-21</span><br><span class="line">151:	108431 	1076808 	ens3f1-TxRx-22</span><br><span class="line">152:	119362 	1098794 	ens3f1-TxRx-23</span><br><span class="line">153:	1484 	1 	ens3f1-TxRx-24</span><br><span class="line">154:	1454 	2 	ens3f1-TxRx-25</span><br><span class="line">155:	1505 	2 	ens3f1-TxRx-26</span><br><span class="line">156:	1515 	2 	ens3f1-TxRx-27</span><br><span class="line">157:	1317 	39 	ens3f1-TxRx-28</span><br><span class="line">158:	1317 	23 	ens3f1-TxRx-29</span><br><span class="line">159:	1261 	19 	ens3f1-TxRx-30</span><br><span class="line">160:	1315 	23 	ens3f1-TxRx-31</span><br><span class="line">161:	1398 	64 	ens3f1-TxRx-32</span><br><span class="line">162:	1442 	23 	ens3f1-TxRx-33</span><br><span class="line">163:	1391 	18 	ens3f1-TxRx-34</span><br><span class="line">164:	1436 	22 	ens3f1-TxRx-35</span><br><span class="line">165:	120044 	1133138 	ens3f1-TxRx-36</span><br><span class="line">166:	112512 	1072834 	ens3f1-TxRx-37</span><br><span class="line">167:	118807 	1070846 	ens3f1-TxRx-38</span><br><span class="line">168:	132013 	1245961 	ens3f1-TxRx-39</span><br><span class="line">169:	5 	0 	ens3f1-TxRx-40</span><br><span class="line">170:	5 	0 	ens3f1-TxRx-41</span><br><span class="line">171:	5 	0 	ens3f1-TxRx-42</span><br><span class="line">172:	5 	0 	ens3f1-TxRx-43</span><br><span class="line">173:	5 	0 	ens3f1-TxRx-44</span><br><span class="line">174:	5 	0 	ens3f1-TxRx-45</span><br><span class="line">175:	5 	0 	ens3f1-TxRx-46</span><br><span class="line">176:	5 	0 	ens3f1-TxRx-47</span><br><span class="line">LOC:			interrupts</span><br></pre></td></tr></table></figure></p>
<p>可以看到，中断较多的收发数据也同样比较多。</p>
<p>因为问题比较严重，不能让用户等着缓慢排查原因，先优先解决问题。根据目前的状况，只要把165-168四个中断从24-27号CPU上调走，大概就能将这四个核心的负载降下来。考虑上面的CPU核心绑定关系，目前0-7号还空闲，用来处理一般任务，先把4-7号CPU用起来。参考了 set_irq_affinity 的代码，<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">/bin/bash</span></span><br><span class="line"></span><br><span class="line">IRQ=$1 #168</span><br><span class="line">core=$2 #31</span><br><span class="line"></span><br><span class="line">MASK_TMP=$((1&lt;&lt;$core))</span><br><span class="line">MASK=$(printf "%X" $MASK_TMP)</span><br><span class="line"></span><br><span class="line">print $MASK</span><br><span class="line"></span><br><span class="line">printf "%s" $MASK &gt; /proc/irq/$IRQ/smp_affinity</span><br><span class="line">printf "%s %d %s -&gt; /proc/irq/$IRQ/smp_affinity\n" $IFACE $core $MASK</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> sudo ./set_irq.sh 165 4</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sudo ./set_irq.sh 166 5</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sudo ./set_irq.sh 167 6</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sudo ./set_irq.sh 168 7</span></span><br></pre></td></tr></table></figure></p>
<p>经过这样调整后，发现24-27四个CPU核心的负载已经降下来，同时其他核心的CPU利用率也稍有提高，出口带宽也有所增加。问题应该是解决了。</p>
<h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>问题大致解决了，暴漏下这些问题</p>
<ol>
<li><p>set_irq_affinity为什么对48个队列都设置了CPU核心？<br>脚本执行时，通过“ls -Ux /sys/class/net/$IFACE/device/msi_irqs”获取了当前网卡的中断号，并检查/proc/interrupts中对应中断的属性是否包含TxRx，所有列出的中断都会分配CPU。</p>
</li>
<li><p>RSS和网卡队列究竟应该是多少个？<br>按之前理解的ixgbe文档，RSS启用后，网卡应该只有16个通道，如果按16个队列、16个核心来绑定，应该是1对1，不该出现如此不均衡的情况。<br>重新阅读了ixgbe的README文档，其中RSS部分说明如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RSS</span><br><span class="line">---</span><br><span class="line">Valid Range: 0-16</span><br><span class="line">0 = Assign up to the lesser value of the number of CPUs or the number of queues</span><br><span class="line">X = Assign X queues, where X is less than or equal to the maximum number of</span><br><span class="line">queues (16 queues).</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>在我们的网关配置中，设置了RSS=0 （或者因为重启该设置失效），实际的队列数为CPU核数（48队列）。另外，通过ethtool -n 选项查看对应的队列信息，也发现网卡实际启用了48个队列。</p>
<h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><ol>
<li><p>上述/proc/interrupts数据是系统启动后的总量，如果中间做过绑定更替，数据就没法准确反馈实际的中断频率。<br>可以通过获取一个时间段内的两个数据，使用excel或python脚本处理下，观察增量来确定每个中断和CPU的数据关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InterFile</span><span class="params">()</span>:</span></span><br><span class="line">    fname = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,fname)</span>:</span></span><br><span class="line">        self.fname = fname</span><br><span class="line">        self.inters = dict()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parseHeadLine</span><span class="params">(self,line)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">            CPU0       CPU1       CPU46      CPU47      </span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        cpus = list()</span><br><span class="line">        cvs = line.split()</span><br><span class="line">        <span class="keyword">for</span> cv <span class="keyword">in</span> cvs:</span><br><span class="line">            cpus.append(cv.strip())</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> cpus</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parseInterLine</span><span class="params">(self,line)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        0:         39          0          0          0          0          0  IR-IO-APIC    2-edge      timer</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        itype = <span class="string">''</span></span><br><span class="line">        inters = list()</span><br><span class="line">        tval3 = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">        tmps = list()</span><br><span class="line">        cvs = line.split()</span><br><span class="line">        <span class="keyword">for</span> cv <span class="keyword">in</span> cvs:</span><br><span class="line">            tmps.append(cv.strip())</span><br><span class="line">        </span><br><span class="line">        itype = tmps[<span class="number">0</span>].strip(<span class="string">':'</span>)</span><br><span class="line">        inters = [int(val) <span class="keyword">for</span> val <span class="keyword">in</span> tmps[<span class="number">1</span>:<span class="number">-3</span>]]</span><br><span class="line">        tval3 = tmps[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (itype,inters,tval3)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parsefile</span><span class="params">(self,fname)</span>:</span></span><br><span class="line">        interinfos = dict()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> open(fname,<span class="string">'r'</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">            lines = rfile.readlines()</span><br><span class="line">            cpus = self.parseHeadLine(lines[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> lines[<span class="number">1</span>:]:</span><br><span class="line">                itype,inters,tval = self.parseInterLine(line)</span><br><span class="line">                interinfos[itype] = &#123;<span class="string">'name'</span>:tval,<span class="string">'inters'</span>:inters&#125;</span><br><span class="line"></span><br><span class="line">        interinfos[<span class="string">'cpus'</span>] = cpus</span><br><span class="line">        <span class="keyword">return</span> interinfos</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(self,inters)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> open(fname + <span class="string">'.json'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> wfile:</span><br><span class="line">            json.dump(inters,wfile)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self)</span>:</span></span><br><span class="line">        inters = self.parsefile(self.fname)</span><br><span class="line">        self.save(inters)</span><br><span class="line">        <span class="keyword">return</span> inters</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IntersDiff</span><span class="params">()</span>:</span></span><br><span class="line">    ipre = <span class="keyword">None</span></span><br><span class="line">    iCur = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,pre,cur)</span>:</span></span><br><span class="line">        self.ipre = pre</span><br><span class="line">        self.iCur = cur</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">diff</span><span class="params">(self)</span>:</span></span><br><span class="line">        diffs = dict()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> key,cval <span class="keyword">in</span> self.iCur.items():</span><br><span class="line">            <span class="keyword">if</span> key == <span class="string">'cpus'</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            prev = self.ipre[key]</span><br><span class="line"></span><br><span class="line">            cis = cval[<span class="string">'inters'</span>]</span><br><span class="line">            pis = prev[<span class="string">'inters'</span>]</span><br><span class="line"></span><br><span class="line">            dis = list()</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(cis)):</span><br><span class="line">                dis.append(cis[i] - pis[i])</span><br><span class="line"></span><br><span class="line">            diffs[key] = &#123;<span class="string">'name'</span>:cval[<span class="string">'name'</span>],<span class="string">'inters'</span>:dis&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> diffs</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    fname = <span class="string">'inter.1.log'</span></span><br><span class="line">    ifile = InterFile(fname)</span><br><span class="line">    pre = ifile.parse()</span><br><span class="line"></span><br><span class="line">    fname = <span class="string">'inter.2.log'</span></span><br><span class="line">    ifile = InterFile(fname)</span><br><span class="line">    cur = ifile.parse()</span><br><span class="line"></span><br><span class="line">    diffs = IntersDiff(pre,cur).diff()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'res.txt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> wfile:</span><br><span class="line">        cpus = cur[<span class="string">'cpus'</span>]</span><br><span class="line">        cstr = <span class="string">'iNum\t'</span> + <span class="string">'\t'</span>.join([val <span class="keyword">for</span> val <span class="keyword">in</span> cpus]) + <span class="string">'\n'</span></span><br><span class="line">        wfile.write(cstr)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> inum,ival <span class="keyword">in</span> diffs.items():</span><br><span class="line">            dstr = inum + <span class="string">'\t'</span> + <span class="string">'\t'</span>.join([str(val) <span class="keyword">for</span> val <span class="keyword">in</span> ival[<span class="string">'inters'</span>]]) + <span class="string">'\t'</span> + ival[<span class="string">'name'</span>] + <span class="string">'\n'</span></span><br><span class="line">            wfile.write(dstr)</span><br></pre></td></tr></table></figure>
</li>
<li><p>网卡处理的数据包数目，ethtool -S的结果也可以用类似的脚本来处理</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://whmz.github.io/2018/03/24/net-cpuset/" data-id="cjf6t7kn30000z4wi3s4chsem" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Strongswan-DAE" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/11/Strongswan-DAE/" class="article-date">
  <time datetime="2018-03-11T13:17:06.000Z" itemprop="datePublished">2018-03-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/11/Strongswan-DAE/">Strongswan-DAE功能相关逻辑整理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li><p>概念</p>
<ul>
<li><p>DAE（Dynamic Authorization Extensions，动态授权扩展）协议是RFC 5176中定义的RADIUS协议的一个扩展，它用于强制认证用户下线，或者更改在线用户授权信息。DAE采用客户端/服务器通信模式，由DAE客户端和DAE服务器组成。</p>
<p>  DAE客户端：用于发起DAE请求，通常驻留在一个RADIUS服务器上，也可以为一个单独的实体。</p>
<p>  DAE服务器：用于接收并响应DAE客户端的DAE请求，通常为一个NAS（Network Access Server，网络接入服务器）设备。</p>
</li>
<li><p>DAE报文包括以下两种类型：</p>
<p>  DMs（Disconnect Messages）：用于强制用户下线。DAE客户端通过向NAS设备发送DM请求报文，请求NAS设备按照指定的匹配条件强制用户下线。</p>
<p>  COA（Change of Authorization）Messages：用于更改用户授权信息。DAE客户端通过向NAS设备发送COA请求报文，请求NAS设备按照指定的匹配条件更改用户授权信息。</p>
<p>  在设备上使能RADIUS DAE服务后，设备将作为RADIUS DAE服务器在指定的UDP端口监听指定的RADIUS DAE客户端发送的DAE请求消息，然后根据请求消息进行用户授权信息的修改或断开用户连接，并向RADIUS DAE客户端发送DAE应答消息。</p>
</li>
</ul>
</li>
<li><p>Strongswan-DAE 问题分析</p>
<ul>
<li><p>现象</p>
<ul>
<li>某个用户登录认证连续多次提示已在线，踢下线没有效果；</li>
<li>检查发现以下情况：<ul>
<li>日志显示：用户13：50：57 认证成功，13：50：59 下线成功</li>
<li>用户13：50之后一直access-reject，直到14：30左右成功登录</li>
<li>radius处检查后，认为是进入会话异常呆死状态，根据已有逻辑，大概30分钟后才能结束该会话</li>
<li>用户通过自理平台发起下线，14：09下线失败，返回 Dissconn-NAK；14：16有一次提示Dissconn-ACK，但是之后并没有实际踢下线；后续的踢下线都是NAK</li>
</ul>
</li>
</ul>
</li>
<li><p>检查步骤和发现的问题</p>
<ul>
<li><p>网关日志检查</p>
<ul>
<li>确认用户13：50：57 认证成功，13：50：59 下线成功；下线时发送了Accounting-END，并且收到了Radius的响应报文</li>
<li><p>确认14：16该用户有一次Dissconn-ACK报文，其他都是NAK</p>
<p>结论：需要检查下Strongswan的DAE处理逻辑，看是什么问题</p>
</li>
</ul>
</li>
<li><p>使用Source Insight查看strongswan代码</p>
<ul>
<li><p>搜索dae代码会出现大量的daemon相关的代码，结果太多</p>
</li>
<li><p>搜索dae、大小写敏感、只搜索注释部分，找到了DAE的处理文件：              \strongswan\src\libcharon\plugins\eap_radius\eap_radius_dae.c</p>
</li>
<li><p>找到了DAE-disconn处理入口：process_disconnect，关键代码：</p>
<ul>
<li>ids = get_matching_ike_sas(this, radius_message_t *request, client);<ul>
<li>根据request的属性信息查找对应的ike_sa</li>
</ul>
</li>
<li>后续代码：<ul>
<li>如果找到sa，则执行清理下线，发送给RMC_DISCONNECT_ACK报文；否则发送RMC_DISCONNECT_NAK。 打印日志信息的代码与日志匹配。确定是该处逻辑处理DAE</li>
</ul>
</li>
</ul>
</li>
<li><p>get_matching_ike_sas(this, radius_message_t *request, client):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">enumerator = request-&gt;create_enumerator(request);</span><br><span class="line">while (enumerator-&gt;enumerate(enumerator, &amp;type, &amp;data))</span><br><span class="line">&#123;</span><br><span class="line">    if (type == RAT_USER_NAME &amp;&amp; data.len)</span><br><span class="line">    &#123;</span><br><span class="line">        user = identification_create_from_data(data);</span><br><span class="line">        DBG1(DBG_CFG, &quot;received RADIUS DAE %N for %Y from %H&quot;,</span><br><span class="line">            radius_message_code_names, request-&gt;get_code(request),</span><br><span class="line">            user, client);</span><br><span class="line">        add_matching_ike_sas(ids, user);</span><br><span class="line">        user-&gt;destroy(user);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>第一个关键点，处理dae-request时，仅使用了其中的RAT_USER_NAME数据，没有使用session-id… 结合用户行为，可以推测：</p>
<ul>
<li>用户边执行重试拨号、边执行了自理平台的下线操作</li>
</ul>
</li>
<li><p>检查日志信息，发现有以下信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">14:16:13 charon: 20[CFG] received RADIUS DAE Disconnect-Request for 1769136xxxx from 59.110.24.89</span><br><span class="line">14:16:13 charon: 20[CFG] closing 1 IKE_SA matching Disconnect-Request, sending Disconnect-ACK</span><br><span class="line">14:16:13 charon: 26[IKE] destroying IKE_SA in state CONNECTING without notification</span><br></pre></td></tr></table></figure>
<p>网关认为是CONNECTING状态的会话，不需要做其他操作，因此不会给radius侧回复Account-END，这一点与Radius的日志信息匹配</p>
</li>
<li><p>这个DAE使用用户名踢下线，具体会踢哪些会话，是否会全踢，还是只踢第一个：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">ids = get_matching_ike_sas(this, request, client);</span><br><span class="line"></span><br><span class="line">if (ids-&gt;get_count(ids))</span><br><span class="line">&#123;</span><br><span class="line">    DBG1(DBG_CFG, &quot;closing %d IKE_SA%s matching %N, sending %N&quot;,</span><br><span class="line">        ids-&gt;get_count(ids), ids-&gt;get_count(ids) &gt; 1 ? &quot;s&quot; : &quot;&quot;,</span><br><span class="line">        radius_message_code_names, RMC_DISCONNECT_REQUEST,</span><br><span class="line">        radius_message_code_names, RMC_DISCONNECT_ACK);</span><br><span class="line"></span><br><span class="line">    enumerator = ids-&gt;create_enumerator(ids);</span><br><span class="line">    while (enumerator-&gt;enumerate(enumerator, &amp;id))</span><br><span class="line">    &#123;</span><br><span class="line">        lib-&gt;processor-&gt;queue_job(lib-&gt;processor, (job_t*)</span><br><span class="line">                                delete_ike_sa_job_create(id, TRUE));</span><br><span class="line">    &#125;</span><br><span class="line">    enumerator-&gt;destroy(enumerator);</span><br><span class="line"></span><br><span class="line">    send_response(this, request, RMC_DISCONNECT_ACK, client);</span><br><span class="line">&#125;</span><br><span class="line">else&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  从代码看，get_matching_ike_sas返回的ids，都会执行清理操作。这一点需要注意，后续统一用户存在多个会话时，确实会存在误踢，把用户全部会话都踢掉</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>DAE-COA</p>
<ul>
<li>检查了COA的代码处理逻辑，process_coa,在处理时跟disconn一样，也只匹配了用户名字段，没有检查session-id是否一样。也就是说，后续如果启用COA功能，也面临一样的问题，会同时重置多个连接的在线时长。这一点可能还是有益的，当用户在线续费、或费用到期，可以同时停止或启用。</li>
</ul>
</li>
</ul>
</li>
<li><p>DAE和超时时间<br> 在实际执行中，发现有时候用户执行踢下线操作时，会延迟很长时间（几分钟），实际的下线操作才会成功。根据用户ID、IP、会话信息查找具体的会话DAE过程，发现这样一个情况：踢下线操作收到后，SS端先执行会话查找操作，找到会话后就发送ACK给Radius端，同时给会话的另一端发送一个断开连接的请求；如果用户还在线则很快响应这个报文下线；如果用户已经断开了网络（断开原先链接的Wifi、非断开IPSec连接），则会重发多次报文之后，才会执行断开操作。而只有断开操作成功后，才会给Radius端发送记账结束报文。</p>
<p> 以下是超时时间的选择：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># /etc/strongswan.d/charon.conf</span><br><span class="line"></span><br><span class="line"># Base to use for calculating exponential back off, see IKEv2 RETRANSMISSION</span><br><span class="line"># in strongswan.conf(5).</span><br><span class="line"># retransmit_base = 1.8</span><br><span class="line"></span><br><span class="line"># Timeout in seconds before sending first retransmit.</span><br><span class="line">retransmit_timeout = 4.0</span><br><span class="line"></span><br><span class="line"># Number of times to retransmit a packet before giving up.</span><br><span class="line">retransmit_tries = 5</span><br><span class="line"></span><br><span class="line"># Interval to use when retrying to initiate an IKE_SA (e.g. if DNS</span><br><span class="line"># resolution failed), 0 to disable retries.</span><br><span class="line"># retry_initiate_interval = 0</span><br></pre></td></tr></table></figure>
<p> 通过man strongswan.conf 查找了超时时间一节：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">IKEv2 RETRANSMISSION</span><br><span class="line">   Retransmission timeouts in the IKEv2 daemon charon can be configured globally using the three keys listed below:</span><br><span class="line"></span><br><span class="line">          charon.retransmit_base [1.8]</span><br><span class="line">          charon.retransmit_timeout [4.0]</span><br><span class="line">          charon.retransmit_tries [5]</span><br><span class="line">          charon.retransmit_jitter [0]</span><br><span class="line">          charon.retransmit_limit [0]</span><br><span class="line"></span><br><span class="line">   The following algorithm is used to calculate the timeout:</span><br><span class="line"></span><br><span class="line">        relative timeout = retransmit_timeout * retransmit_base ^ (n-1)</span><br><span class="line"></span><br><span class="line">   Where  n  is  the  current  retransmission count. The calculated timeout can&apos;t exceed the configured retransmit_limit (if</span><br><span class="line">   any), which is useful if the number of retries is high.</span><br><span class="line"></span><br><span class="line">   If a jitter in percent is configured, the timeout is modified as follows:</span><br><span class="line"></span><br><span class="line">        relative timeout -= random(0, retransmit_jitter * relative timeout)</span><br><span class="line"></span><br><span class="line">   Using the default values, packets are retransmitted in:</span><br><span class="line"></span><br><span class="line">   Retransmission   Relative Timeout   Absolute Timeout</span><br><span class="line">   ─────────────────────────────────────────────────────</span><br><span class="line">   1                              4s                 4s</span><br><span class="line">   2                              7s                11s</span><br><span class="line">   3                             13s                24s</span><br><span class="line">   4                             23s                47s</span><br><span class="line">   5                             42s                89s</span><br><span class="line">   giving up                     76s               165s</span><br></pre></td></tr></table></figure>
<p> 根据我们跟踪的日志信息，发下上述时间跟日志输出的时间间隔一致。考虑到安全问题，IPSec这样设计超时也许没问题，在我们的接入应用中，这么长的超时时间没法接受，我们把两个参数修改了</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Timeout in seconds before sending first retransmit.</span><br><span class="line">retransmit_timeout = 3.0</span><br><span class="line"></span><br><span class="line"># Number of times to retransmit a packet before giving up.</span><br><span class="line">retransmit_tries = 3</span><br></pre></td></tr></table></figure>
<p> 根据它的超时算法，修改后的超时时间为：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Retransmission   Relative Timeout   Absolute Timeout</span><br><span class="line">─────────────────────────────────────────────────────</span><br><span class="line">1                              3s                 3s</span><br><span class="line">2                            5.4s               8.4s</span><br><span class="line">3                            9.7s              18.1s</span><br><span class="line">giving up                   17.5s              35.6s</span><br></pre></td></tr></table></figure>
<p> 这样已经能兼顾丢包和处理效率，在局域网内效果已经可以保证。</p>
</li>
<li><p>如何根据DAE获取并匹配session-id<br> 后续如果需要修改这块的逻辑，需要根据DAE报文中的session-id，查找ike_sa，应用新的授权信息。</p>
<ul>
<li><p>已有的dae代码已经能根据用户名获取到用户名匹配的ike_sa</p>
</li>
<li><p>SESSION-ID</p>
<ul>
<li><p>根据radius的DAE报文，找到了session-id对应的attribute-type：\strongswan\src\libradius\radius_message.h,</p>
<ul>
<li>RAT_ACCT_SESSION_ID = 44,</li>
</ul>
</li>
<li><p>初始化:<br>  在发送Accounting-Start时开始获取或创建：get_or_create</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">* Send an accounting start message</span><br><span class="line">*/</span><br><span class="line">static void send_start(private_eap_radius_accounting_t *this, ike_sa_t *ike_sa)</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    entry_t *entry;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    entry = get_or_create_entry(this, ike_sa-&gt;get_id(ike_sa),</span><br><span class="line">                                ike_sa-&gt;get_unique_id(ike_sa));</span><br></pre></td></tr></table></figure>
<p>  创建时，实际调用了这些操作(unique会记录到syslog中)：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snprintf(entry-&gt;sid, sizeof(entry-&gt;sid), &quot;%u-%u&quot;, this-&gt;prefix, unique);</span><br></pre></td></tr></table></figure>
<p>  其中的prefix信息是这么生成的：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">eap_radius_accounting_t *eap_radius_accounting_create()</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    /* use system time as Session ID prefix */</span><br><span class="line">    .prefix = (uint32_t)time(NULL),</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>  unique_id是个递增的值，每创建一个ike_sa加1：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ike_sa_t * ike_sa_create(ike_sa_id_t *ike_sa_id, bool initiator,</span><br><span class="line">        ike_version_t version)</span><br><span class="line">&#123;</span><br><span class="line">    private_ike_sa_t *this;</span><br><span class="line">    static refcount_t unique_id = 0;</span><br><span class="line">    </span><br><span class="line">    .unique_id = ref_get(&amp;unique_id),</span><br></pre></td></tr></table></figure>
<p>  自增在这里：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">* Increase refcount</span><br><span class="line">*/</span><br><span class="line">refcount_t ref_get(refcount_t *ref)</span><br><span class="line">&#123;</span><br><span class="line">    refcount_t current;</span><br><span class="line"></span><br><span class="line">    ref_lock-&gt;lock(ref_lock);</span><br><span class="line">    current = ++(*ref);</span><br><span class="line">    ref_lock-&gt;unlock(ref_lock);</span><br><span class="line"></span><br><span class="line">    return current;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>参考上述代码，仿照get_or_create 功能，仅使用get部分的代码：</p>
<ul>
<li><p>\src\libcharon\plugins\eap_radius\eap_radius_plugin.c: plugin_cb<br>此处为已有代码，在创建dae时已经给赋值了accounting对象：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">this-&gt;accounting = eap_radius_accounting_create();</span><br><span class="line">this-&gt;forward = eap_radius_forward_create();</span><br><span class="line">this-&gt;provider = eap_radius_provider_create();</span><br><span class="line"></span><br><span class="line">load_configs(this);</span><br><span class="line"></span><br><span class="line">if (lib-&gt;settings-&gt;get_bool(lib-&gt;settings,</span><br><span class="line">                &quot;%s.plugins.eap-radius.dae.enable&quot;, FALSE, lib-&gt;ns))</span><br><span class="line">&#123;</span><br><span class="line">    this-&gt;dae = eap_radius_dae_create(this-&gt;accounting);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在src\libcharon\plugins\eap_radius\eap_radius_accounting.c 中添加get_session_id方法(示例，后续要加锁)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">static char * get_session_id(private_eap_radius_accounting_t *this,</span><br><span class="line">                            ike_sa_id_t *id)</span><br><span class="line">&#123;</span><br><span class="line">    entry_t *entry;</span><br><span class="line">    entry = this-&gt;sessions-&gt;get(this-&gt;sessions, id);</span><br><span class="line">    return entry-&gt;sid; //char sid[24];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在src\libcharon\plugins\eap_radius\eap_radius_dae.c中需要使用sid的地方调用(示例，后续要加锁、要判断是否为空)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">static char * get_session_id(private_eap_radius_dae_t *this,</span><br><span class="line">                        ike_sa_id_t *id)</span><br><span class="line">&#123;</span><br><span class="line">    return this-&gt;accounting-&gt;get_session_id(this-&gt;accounting,id);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
<li><p>其他发现</p>
<ul>
<li>account-stop 通过触发方式调用，在连接断开时，通过 up_down 调用</li>
<li><p>发送accounting时，会附带RAT_NAS_IP_ADDRESSs属性，这个值一般情况下是提供VPN服务的端口IP；当用户通过非园区网络连接时，也就是用户网络切换后，如果服务器到用户的路由切换到外网口，这个值会变成对应的外网口IP：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Acct-Session-Id = &quot;1514557340-10756&quot;</span><br><span class="line">  	NAS-IP-Address = 218.195.95.16</span><br><span class="line">   Called-Station-Id = &quot;218.195.95.16[4500]&quot;</span><br><span class="line">   Calling-Station-Id = &quot;172.17.57.196[60232]&quot;</span><br></pre></td></tr></table></figure>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Acct-Session-Id = &quot;1514557340-10756&quot;</span><br><span class="line">   NAS-IP-Address = 111.21.65.2</span><br><span class="line">   Called-Station-Id = &quot;111.21.65.2[4500]&quot;</span><br><span class="line">   Calling-Station-Id = &quot;113.200.106.45[25978]&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>当网关收到用户侧发过来的数据时，会根据src和dst更新ike_sa中的host信息</p>
</li>
</ul>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://whmz.github.io/2018/03/11/Strongswan-DAE/" data-id="cjemuqgjd0000mcwidwhd7sdx" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-ipmarks" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/10/ipmarks/" class="article-date">
  <time datetime="2018-03-10T13:05:06.000Z" itemprop="datePublished">2018-03-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/10/ipmarks/">一个流量标记问题导致的限速Bug</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>继续之前限速脚本的话题，本次整理下处理的一个限速Bug。</p>
<p>近期对网络出口做了扩容，按监控的带宽数据来算，目前有20%左右的裕量，按说用户那边不再那么卡了，但是这周总是接到用户投诉说网速达不到，并发了相应的截图。为了排查具体的情况，在周三、四做了两次的问题排查，终于发现了问题点。本文简单记录下问题发现和排查过程。</p>
<h2 id="问题时间点"><a href="#问题时间点" class="headerlink" title="问题时间点"></a>问题时间点</h2><p>我们运营的学校在这周开学，大概从周二开始，有用户投诉带宽问题。考虑带宽和限速模块没有做过调整，本来是很确信不会有问题，毕竟已经正常运行了那么久的系统了！但是周三，我们自己的客服也在反馈这个问题，并拿到了实际测试的结果：在各种带宽的测试环境下，基本达不到预期的值，特别是在50M环境下，一般还达不到20M。这样基本说明，问题点确实存在，需要详细排查下。</p>
<h2 id="第一次检查"><a href="#第一次检查" class="headerlink" title="第一次检查"></a>第一次检查</h2><p>周三因为要解决另外的问题，在观察问题流量的同时，对系统做了次简单的检查。大致的流程如下：</p>
<ol>
<li><p>检查用户拨号后，下发的限速值是否正确<br> 这个可以通过syslog日志输出的限速参数检查，发现测速有问题的账号，实际限速参数并没有问题，上行20M，下行50M。在检查后再次测速，速率仍有较大差异。</p>
</li>
<li><p>检查限速参数是否正确应用到了tc的正确队列<br> 按上篇文章的介绍，用户IP和tc队列有个确定的对应关系，tc_class = (srcIP &amp; 0xff) + 1, 根据这个计算出用户队列，检查对应的上下行参数，正确。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> |     </span><br><span class="line"> +---(10:1daf) htb prio 1 rate 20Mbit ceil 20Mbit burst 1600b cburst 1600b </span><br><span class="line"> |             Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0) </span><br><span class="line"> |             rate 0bit 0pps backlog 0b 0p requeues 0 </span><br><span class="line">--</span><br><span class="line"> |             rate 0bit 0pps backlog 0b 0p requeues 0 </span><br><span class="line"> |     </span><br><span class="line"> +---(10:1daf) htb prio 1 rate 50Mbit ceil 50Mbit burst 1600b cburst 1600b </span><br><span class="line"> |             Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0) </span><br><span class="line"> |             rate 0bit 0pps backlog 0b 0p requeues 0</span><br></pre></td></tr></table></figure>
</li>
<li><p>经过这两步检查，发现用户速率没有问题，这时候怀疑是不是上行带宽实际上没有扩容？<br> 使用了<a href="https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py" target="_blank" rel="noopener">speettest的脚本</a> 检查服务器带宽：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py</span><br><span class="line">python speedtest.py</span><br></pre></td></tr></table></figure>
<p> 检查发现，在当时负载比较高、接近扩容前带宽的情况下，速率仍能达到1957Mbps，可以判断出口带宽已经扩容了。</p>
</li>
<li><p>这样，排除外部原因，开始检查下校园网络的情况。因为接入方式流量跑在校园网上，如果校园网情况不好，带宽也起不来。<br> 安排了客服下载校园内服务器的资源，可以跑满100M….</p>
</li>
</ol>
<p>经过这几步排查，发现问题确实存在，但排除了下发错误、限速参数设置、出口带宽、内部网络故障这几个原因，有可能是服务程序问题。这时候也有客服反馈，现场有单个账号出问题的，只有某个账号速率不足，50M只能到10Mbps，同样环境换账号就可以。这样差不多可以怀疑限速功能是有问题了。</p>
<p>之后是校园停电，12点了，没有办法继续试验排查，再加上有其他问题检查解决，也就暂时放下了这个问题。</p>
<h2 id="第二次检查"><a href="#第二次检查" class="headerlink" title="第二次检查"></a>第二次检查</h2><p>周四，在解决了其他问题后，重新开始检查限速的问题。这时候，因为排除了一些因素，重点放到了限速的功能上，但是还没相信是代码问题….大致做了这么些检查：</p>
<ol>
<li><p>确定一个账号先检查<br> 在这个用户登录后，获取其登录IP地址，10.151.25.99, 换算其tc-class为 10:1965, 检查其tc限速参数</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[]@vser:~$ sudo /etc/xlipsec/mark_tc.sh status ens3f0 ens3f1| grep -C 2 10:1965</span><br><span class="line"> |             rate 0bit 0pps backlog 0b 0p requeues 0 </span><br><span class="line"> |     </span><br><span class="line"> +---(10:1965) htb prio 1 rate 20Mbit ceil 20Mbit burst 1600b cburst 1600b </span><br><span class="line"> |             Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0) </span><br><span class="line"> |             rate 0bit 0pps backlog 0b 0p requeues 0 </span><br><span class="line">--</span><br><span class="line"> |             rate 0bit 0pps backlog 0b 0p requeues 0 </span><br><span class="line"> |     </span><br><span class="line"> +---(10:1965) htb prio 1 rate 50Mbit ceil 50Mbit burst 1600b cburst 1600b </span><br><span class="line"> |             Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0) </span><br><span class="line"> |             rate 0bit 0pps backlog 0b 0p requeues 0</span><br></pre></td></tr></table></figure>
<p> 可以看到，限速的队列带宽没有问题，上行20M，下行50M</p>
</li>
<li><p>测速结果，上行8.05M、下行8.91M，完全不在同一水平上么<br> 这时候，我发现” Send 0 bytes 0 pkt “，而且上下行数据都是0，这说明流量根本就没走到这个队列！</p>
</li>
<li><p>考虑到限速映射过程只有两个步骤，标记、映射，先检查标记部分：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[]@vser:~$ sudo iptables -t mangle -L -v</span><br><span class="line">Chain POSTROUTING (policy ACCEPT 56G packets, 57T bytes)</span><br><span class="line">pkts bytes target     prot opt in     out     source               destination         </span><br><span class="line">18G 2164G IPMARK     all  --  any    any     10.151.0.0/18        anywhere             -j IPMARK --addr src  --and-mask 0xfff </span><br><span class="line">16G   27T IPMARK     all  --  any    any     anywhere             10.151.0.0/18        -j IPMARK --addr dst  --and-mask 0xfff</span><br></pre></td></tr></table></figure>
<p> 看到这个结果就知道是哪里出问题了。地址池使用了18位掩码，就意味着变化的部分是后14位，如果使用0xfff掩码计算用户的mark值，就会导致部分高地址用户被映射到低位区间，跟其他用户冲突。按测试账号的数据，10.151.25.99，刚好是超出范围的高位IP用户，实际会被标记为 0965，与10.151.9.99用户共用了一个限速队列。</p>
<p> 当9.99这个用户在线的时候，两人实际上共用同一个队列，共享带宽，这就是有时候测速接近20M的原因，9.99用户使用的是20M套餐；而当9.99用户下线后，这个限速队列被重置为10Mbps，这时候测速就会出现先前的数据：上行8.05M、下行8.91M 。</p>
</li>
<li><p>问题找到后，对IPMARK代码做了修改，</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iptables -t mangle -A POSTROUTING -s 10.151.0.0/18 -j IPMARK --addr src --and-mask 0x3fff</span><br><span class="line">iptables -t mangle -D POSTROUTING 1</span><br></pre></td></tr></table></figure>
<p> 这样再测试先前的账号，已经可以看到对应的 10:1965 队列已经有流量经过：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">     |     </span><br><span class="line"> +---(10:1965) htb prio 1 rate 10Mbit ceil 10Mbit burst 1600b cburst 1600b </span><br><span class="line"> |             Sent 162249444 bytes 1574854 pkt (dropped 0, overlimits 0 requeues 0) </span><br><span class="line"> |             rate 0bit 0pps backlog 0b 0p requeues 0 </span><br><span class="line">--</span><br><span class="line"> |             rate 0bit 0pps backlog 0b 0p requeues 0 </span><br><span class="line"> |     </span><br><span class="line"> +---(10:1965) htb prio 1 rate 20Mbit ceil 20Mbit burst 1600b cburst 1600b </span><br><span class="line"> |             Sent 1362668930 bytes 1770932 pkt (dropped 0, overlimits 0 requeues 0) </span><br><span class="line"> |             rate 0bit 0pps backlog 0b 0p requeues 0</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改后的测试结果是，speettest站点测速，下行只有27.58Mbps，上行为 11.30Mbps，仍然离实际限速值差距较大。<br>为了排查问题，对这个账号的限速参数做了调整，先后尝试了80M、8M、20M</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo tc class replace dev ens3f0 parent 10:1 classid 10:1995 htb rate 80Mbit ceil 80Mbit prio 1</span><br><span class="line">sudo tc class replace dev ens3f0 parent 10:1 classid 10:1995 htb rate 8Mbit ceil 8Mbit prio 1</span><br><span class="line">sudo tc class replace dev ens3f0 parent 10:1 classid 10:1995 htb rate 20Mbit ceil 20Mbit prio 1</span><br></pre></td></tr></table></figure>
<p> 测试结果显示，限速值较小时，测速结果接近限速数据，比如8M测速为6.99M，20M被限速为 16.97M； 当速率较大的时候，速率差距就很大了，比如80M测速为 24M。再看tc队列状态，每次测速，对应的tc队列数据都会增加，说明数据确实在这个队列被限速。但是对应的dropped数据始终为0，说明数据不是在这个被丢掉的。再加上当时系统负载比较低、测速时数据包延迟在7、8ms，可以推断不是在网关限速的。</p>
</li>
<li><p>联系客服换个测速站试试，试验了360，测试50M限速情况下，实际测速 5.25 * 8 = 42Mbps，考虑封包损耗，可以认为接近限速值了。另外就是，tc的dropped字段也终于出现了非0值。</p>
</li>
</ol>
<p>后续客服联系了speedtest的限速，请求排查限速的问题，怀疑是测速站点被限速了，但在等反馈结果。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li><p>mark参数问题：最早设计时，单网关考虑4096个设备，准备采用20位地址掩码，这样计算用户的mark值只需要0xfff就够了。但是后期发现，尽量给同一账号的用户分配相同地址，这样实际占用的地址数多于在线用户数，最终使用了18位地址掩码、16384个地址，相应的mark掩码就需要调整为0x3fff。但是，部署发现问题后，只在master基线修改了代码，并没有更新部署包。新服务部署时，一般不会去检查、修改某个特殊的参数；在小规模测试时，也不会触发这个问题（登录设备大于4096才会触发问题），所以直到用户规模足够，才发现了问题。</p>
</li>
<li><p>测速反应的是客户端到测速服务器的速度，只要360能达到限速值，就说明网关没限速；但对用户来说速率实际没有达到标称值。</p>
</li>
</ol>
<h2 id="改进措施"><a href="#改进措施" class="headerlink" title="改进措施"></a>改进措施</h2><ol>
<li>修改参数后，应及时评估相关改动，对所有涉及的数据做检查，修正数据；</li>
<li>修复Bug后，应及时发布新版本修改问题，整理升级脚本；</li>
<li>服务部署的版本应该登记、管理：在发现新Bug后，应该评估影响的服务器，对所有相关服务尽快执行升级；</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://whmz.github.io/2018/03/10/ipmarks/" data-id="cjemuqgjs0002mcwigblksrs1" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-ss-hfsc" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/02/25/ss-hfsc/" class="article-date">
  <time datetime="2018-02-25T10:33:06.000Z" itemprop="datePublished">2018-02-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/25/ss-hfsc/">多用户环境下的流量标记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>单位使用了个Linux网关在园区网络提供旁路接入功能。作为运营网络，肯定得考虑限速的问题，使用了iptables、IPMARK、tc-htb等功能实现了限速。</p>
<p>随着用户数逐渐增多，当出口网络比较拥堵的时候，大量用户反馈延迟较高、游戏用户基本无法使用。基于这样的情况，我们尝试是否能在当前的系统上，增加QoS支持：区分用户的应用流量、执行不同速率策略，缓解问题。</p>
<p>本文简单记录了两个试验方案，使用HTB和HFSC限速和整流，给出限速的关键脚本和思路，以及配套的MARK规则。本文先不讨论HTB、HFSC本身的使用方法和设计，主要讨论分类器的设计和实现。</p>
<h2 id="基于用户的限速"><a href="#基于用户的限速" class="headerlink" title="基于用户的限速"></a>基于用户的限速</h2><p>策略比较简单，每个接入用户使用自己的htb-class：</p>
<ul>
<li>在用户接入的时候，Radius模块能收到用户的接入IP、上下行带宽数据，根据这些数据设置htb-class的限速参数</li>
<li>当用户有网络流量经过网关时，根据IP把对应的流量映射到htb-class</li>
</ul>
<p>在具体代码上，大致有这么三段：</p>
<ol>
<li><p>通过iptables-mark标记流量</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 根据流方向，用户上下行有两条规则.对于用户输入流量，假定用户IP为 srcIP ，则 </span><br><span class="line"># mark = srcIP &amp; 0xff</span><br><span class="line"></span><br><span class="line">iptables -t mangle -A POSTROUTING -s $VIPS -j IPMARK --addr src --and-mask 0xfff</span><br></pre></td></tr></table></figure>
</li>
<li><p>tc初始化    </p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 定义用户流量映射规则</span><br><span class="line"># 以mark为key，映射用户流量到 10:(1+mark) 分类</span><br><span class="line"></span><br><span class="line">tc filter add dev $ODEV parent 10: handle 100 flow map key mark baseclass 10:1</span><br></pre></td></tr></table></figure>
</li>
<li><p>tc限速设置</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 用户IP为vip，计算其vflag，对10:$vflag分类设置速率值，其中</span><br><span class="line"># vflag = ($vip + 1) &amp; 0xfff</span><br><span class="line"></span><br><span class="line">tc class replace dev $ODEV parent 10:1 classid 10:$vflag htb rate $urate ceil $uceil prio 1</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="基于用户-QoS的限速"><a href="#基于用户-QoS的限速" class="headerlink" title="基于用户+QoS的限速"></a>基于用户+QoS的限速</h2><p>根据我们的分析，除了扩大出口流量，试试对用户流量分级、降低大流量应用的优先级、保障游戏、交互带宽，应该也能缓解部分问题。</p>
<p>相对简单的用户限速方案，这个方案要在识别用户流量的基础上，进一步识别应用。考虑我们的流量规模大致在5~10Gbps，在这样的网络环境下要实现应用流量识别、再加以QoS限速，从性能上讲不大现实——算法太复杂，算法本身对性能的影响太大，会进一步加大延迟。</p>
<p>内部讨论后，我们基于包长度做了个简单的模型。除了数据包本身的QoS字段之外，包长度在一定程度上也能反映用户数据流量的特征：大数据传输一般使用最大报文长度；TCP初始连接、交互数据一般不会有太大的数据量，从而数据包长度较短。</p>
<p>考虑这个情况，我们的需求1：<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">设计一个相对简洁的标记机制，区分同一用户下的流量，使得针对不同的流量能施加不同的速率控制</span><br></pre></td></tr></table></figure></p>
<p>另外，用户接入过程也会占用一部分流量，这部分流量因为未纳入限速框架（用户接入成功前IP不在$VIP定义的地址池中），默认会归为系统流量。如果不给这部分流量保留带宽，用户在高峰期的连接成功率会比较差。需求2来了：<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">新的流量标记机制，必须区分系统带宽和用户带宽，对系统带宽也进行分类，对接入流量和其他流量设置不同策略。</span><br></pre></td></tr></table></figure></p>
<p>基于这两个需求，我们设计了这样的一个MARK规则（请忽略长度数据….）：<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># length &lt; 400</span><br><span class="line">1.  iptables -t mangle -A POSTROUTING -d $VIPS -m length --length :400 -j IPMARK --addr dst --and-mask 0x3fff --or-mask 0x24000</span><br><span class="line">2.  iptables -t mangle -A POSTROUTING -d $VIPS -m length --length :400 -j RETURN</span><br><span class="line"></span><br><span class="line"># length &gt; 400</span><br><span class="line">3.  iptables -t mangle -A POSTROUTING -d $VIPS -j IPMARK --addr dst --and-mask 0x3fff --or-mask 0x28000</span><br><span class="line">4.  iptables -t mangle -A POSTROUTING -d $VIPS -j RETURN</span><br><span class="line"></span><br><span class="line"># sys load</span><br><span class="line">5.  iptables -t mangle -A POSTROUTING -m length --length :400 -j IPMARK --set-mark 0x14000</span><br><span class="line">6.  iptables -t mangle -A POSTROUTING -m length --length :400 -j RETURN</span><br><span class="line"></span><br><span class="line">7.  iptables -t mangle -A POSTROUTING -j MARK --set-mark 0x18000</span><br><span class="line">8.  iptables -t mangle -A POSTROUTING -j RETURN</span><br></pre></td></tr></table></figure></p>
<p>按设计想法，用户流量符合$VIPS地址池条件，会在前面的四条规则中被设置为 ((ip &amp; 0x3fff) | 0x24000) 或者 ((ip &amp; 0x3fff) | 0x24000)，系统流量则归为 0x14000 和 0x18000 ，从而实现上述两个需求。同时，符合一条规则的包不再执行后续的检查，从性能上讲也好一点。</p>
<p>但是，实际测试时候发现，所有包都被纳入了 0x14000 和 0x18000 这两个分类！<br>为了跟踪包标记情况，使用了iptables -t mangle -L -v，查看了每条规则的包匹配情况，发现每个经过1、2的包，都会再次经过5、6; 而3、4两条规则也是一样，再次经过7、8。这样的话，每个包被标记了两次，肯定是后一个标记起作用。</p>
<p>那么问题是，为什么包在规则2、4行的RETURN之后，还会继续经过后续的5、6、7、8规则呢？原来，我们的接入方式是IPSec，一个网络包进入网卡后，会根据数据方向，通过XFRM框架解包/封包，在协议栈内部实际跑两圈，两次经过mangle postrouting链。在用户下行数据方向，就会出现刚才的情况，实际上所有流量都会走到系统队列处理。这个可以参考<a href="https://upload.wikimedia.org/wikipedia/commons/3/37/Netfilter-packet-flow.svg" target="_blank" rel="noopener">Netfilter-packet-flow</a></p>
<p>为了解决这个问题，修改后的的MARK规则是这样的:<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># ip addr</span><br><span class="line">iptables -t mangle -A POSTROUTING -d $VIPS -j IPMARK --addr dst --and-mask 0x3fff --or-mask 0x20000</span><br><span class="line"></span><br><span class="line"># load length</span><br><span class="line">iptables -t mangle -A POSTROUTING -m length --length :400 -j MARK --or-mark 0x14000</span><br><span class="line">iptables -t mangle -A POSTROUTING -m length --length :400 -j RETURN</span><br><span class="line"></span><br><span class="line">iptables -t mangle -A POSTROUTING -j MARK --or-mark 0x18000</span><br><span class="line">iptables -t mangle -A POSTROUTING -j RETURN</span><br></pre></td></tr></table></figure></p>
<p>按这个规则，地址池$VIPS中的地址包，会在原有的mark基础上添加一个0x20000; 所有的包都会根据包长度，在原有mark上添加一个 0x14000 或 0x18000 。这样，用户包，始终都会经过两次mark标记，最终结果为 0x34000 或 0x38000 ；系统包因为不会满足$VIPS的地址池条件，其mark只能是 0x14000 或 0x18000 。该标记满足了上述两个需求。</p>
<p>但是这样一来，每个用户包已经至少多执行3条过滤规则</p>
<h2 id="需要进一步学习的内容"><a href="#需要进一步学习的内容" class="headerlink" title="需要进一步学习的内容"></a>需要进一步学习的内容</h2><p>hfsc限速参数中，rt、ls、ul、sc的含义和相互关系。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://whmz.github.io/2018/02/25/ss-hfsc/" data-id="cjemuqgko0003mcwidarn8dtp" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hello" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/02/25/hello/" class="article-date">
  <time datetime="2018-02-25T10:28:45.000Z" itemprop="datePublished">2018-02-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/25/hello/">开始！</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>用作个人知识整理和分享的Blog，目前规划这些内容：</p>
<ul>
<li>知识备忘：近段时间了解的新知识，稍作探索的摘要，或简单记录用作备忘。</li>
<li>学习整理：近期内学习、掌握的知识和技能点，做部分整理，以用作经验分享。</li>
<li>问题记录：记录平时工作学习解决的问题。一般来源于工作实践，记录处理具体问题的过程和方法。</li>
<li>学习计划：近段时间预计学习的知识点</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://whmz.github.io/2018/02/25/hello/" data-id="cjemuqgjs0001mcwi121cbw0q" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/03/24/net-cpuset/">网卡中断和CPU绑定问题处理</a>
          </li>
        
          <li>
            <a href="/2018/03/11/Strongswan-DAE/">Strongswan-DAE功能相关逻辑整理</a>
          </li>
        
          <li>
            <a href="/2018/03/10/ipmarks/">一个流量标记问题导致的限速Bug</a>
          </li>
        
          <li>
            <a href="/2018/02/25/ss-hfsc/">多用户环境下的流量标记</a>
          </li>
        
          <li>
            <a href="/2018/02/25/hello/">开始！</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 whmz?<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>